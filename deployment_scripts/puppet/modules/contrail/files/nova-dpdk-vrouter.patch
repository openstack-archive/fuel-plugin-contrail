From c459180f790ef654c0c790930f0371b90758ba16 Mon Sep 17 00:00:00 2001
From: Michal Dubiel <md@semihalf.com>
Date: Tue, 8 Sep 2015 17:05:16 +0200
Subject: [PATCH] Add config option forcing hugepages memory backing

Setting 'libvirt_use_huge_pages' config option in nova.conf will result
in using QEMU's -mem-path option while spawning a VM.

This is necessary for DPDK vRouter support on Juno.

Change-Id: I2e8337f47d10689816c46971a97a6214e0322399
Partial-Bug: #1491525

Add support for vhost-user into vrouter vif driver

This is necessary for DPDK vRouter support on Juno.

Change-Id: I2e37292f699356da095562ec874dfdb8fa35e418
Closes-Bug: #1491525

libvirt: Support for 'shared' mapping of huge pages

Change imported from the Liberty's commit:
Commit: 25df2fae79c03a0335413e7a5de6b54c127e7926
Author: Daniel P. Berrange <berrange@redhat.com>
Subject: libvirt: mark NUMA huge page mappings as shared access

Change-Id: Ibf1a0cad939e5ba290af5a0e7c16ff23697b1ec5
Partial-Bug: #1504031

libvirt, vhostuser: Add support for OpenContrail vRouter

OpenContrail vRouter can be used as a userspace DPDK based virtual switch
application that uses QEMU's vhost-user interface types. This requires adding
support for vRouter in {plug, unplug}_vhostuser() methods similarly as it is
done for OVS.

This reverts commits:
- 70c23c2601c46f63d8e631044b81992088795698 "Add support for vhost-user into
  vrouter vif driver"

- 396601daa1be3e58876ecdbb7dbbc23f4d8c8d2b "Add config option forcing hugepages
  memory backing"

Change-Id: I3387795b59dd86838fb5c8ce6a447d5173e55bdb
Partial-Bug: #1504031

Handle exception in plug and unplug functions for vrouter and vhostuser

During delete of nova VM, linux_net functions like
delete_net_dev/create_tap_dev/create_ovs_vif_port/delete_ovs_vif_port can raise
ProcessExecutionError while executing system command. Handle these exceptions

Change-Id: I59e4160ee5404946d48139219a7156b918c2bee7
Closes-Bug: #1538207

Handle new command line options of vrouter-port-control

New command line options --vif_type and --vhostuser_socket has been added to
vrouter-port-control tool. Nova has to pass them appropriately.

Change-Id: Idde377f2cf72e35624befec09dd11c5f86f57ed8
Related-Bug: #1541952
---
 nova/network/model.py                    |  3 +
 nova/tests/unit/virt/libvirt/test_vif.py | 94 +++++++++++++++++++++++++++++-
 nova/virt/libvirt/config.py              |  4 ++
 nova/virt/libvirt/driver.py              | 43 +++++++++++++-
 nova/virt/libvirt/vif.py                 | 99 ++++++++++++++++++++++----------
 5 files changed, 210 insertions(+), 33 deletions(-)

diff --git a/nova/network/model.py b/nova/network/model.py
index fb9e009..2e1e437 100644
--- a/nova/network/model.py
+++ b/nova/network/model.py
@@ -64,6 +64,9 @@ VIF_DETAILS_VHOSTUSER_SOCKET = 'vhostuser_socket'
 # Specifies whether vhost-user socket should be plugged
 # into ovs bridge. Valid values are True and False
 VIF_DETAILS_VHOSTUSER_OVS_PLUG = 'vhostuser_ovs_plug'
+# Specifies whether vhost-user mode should be used by vrouter.
+# Valid values are True and False
+VIF_DETAILS_VHOSTUSER_VROUTER_PLUG = 'vhostuser_vrouter_plug'
 
 # Define supported virtual NIC types. VNIC_TYPE_DIRECT and VNIC_TYPE_MACVTAP
 # are used for SR-IOV ports
diff --git a/nova/tests/unit/virt/libvirt/test_vif.py b/nova/tests/unit/virt/libvirt/test_vif.py
index 612efa3..1748b25 100644
--- a/nova/tests/unit/virt/libvirt/test_vif.py
+++ b/nova/tests/unit/virt/libvirt/test_vif.py
@@ -295,6 +295,16 @@ class LibvirtVifTestCase(test.NoDBTestCase):
               ovs_interfaceid='aaa-bbb-ccc'
               )
 
+    vif_vhostuser_vrouter = network_model.VIF(id='vif-xxx-yyy-zzz',
+              address='ca:fe:de:ad:be:ef',
+              network=network_bridge,
+              type=network_model.VIF_TYPE_VHOSTUSER,
+              details = {network_model.VIF_DETAILS_VHOSTUSER_MODE: 'client',
+                       network_model.VIF_DETAILS_VHOSTUSER_SOCKET:
+                                                        '/tmp/usv-xxx-yyy-zzz',
+                       network_model.VIF_DETAILS_VHOSTUSER_VROUTER_PLUG: True},
+              )
+
     vif_vhostuser_no_path = network_model.VIF(id='vif-xxx-yyy-zzz',
           address='ca:fe:de:ad:be:ef',
           network=network_bridge,
@@ -302,7 +312,8 @@ class LibvirtVifTestCase(test.NoDBTestCase):
           details = {network_model.VIF_DETAILS_VHOSTUSER_MODE: 'client'}
           )
 
-    instance = objects.Instance(id=1, uuid='instance-uuid')
+    instance = objects.Instance(id=1, uuid='instance-uuid',
+                                project_id=1, display_name='Instance 1')
 
     bandwidth = {
         'quota:vif_inbound_peak': '200',
@@ -1165,3 +1176,84 @@ class LibvirtVifTestCase(test.NoDBTestCase):
             d = vif.LibvirtGenericVIFDriver()
             d.unplug_vhostuser(None, self.vif_vhostuser_ovs)
             delete_port.assert_has_calls(calls['delete_ovs_vif_port'])
+
+    def test_vhostuser_driver_vrouter(self):
+        d = vif.LibvirtGenericVIFDriver()
+        xml = self._get_instance_xml(d,
+                                     self.vif_vhostuser_vrouter)
+        node = self._get_node(xml)
+        self.assertEqual(node.get("type"),
+                         network_model.VIF_TYPE_VHOSTUSER)
+
+        self._assertTypeEquals(node, network_model.VIF_TYPE_VHOSTUSER,
+                               "source", "mode", "client")
+        self._assertTypeEquals(node, network_model.VIF_TYPE_VHOSTUSER,
+                               "source", "path", "/tmp/usv-xxx-yyy-zzz")
+        self._assertTypeEquals(node, network_model.VIF_TYPE_VHOSTUSER,
+                               "source", "type", "unix")
+        self._assertMacEquals(node, self.vif_vhostuser_vrouter)
+        self._assertModel(xml, network_model.VIF_MODEL_VIRTIO)
+
+    def test_vhostuser_vrouter_plug(self):
+        calls = {
+            '_vrouter_port_add': [mock.call(self.instance,
+                                  self.vif_vhostuser_vrouter)]
+        }
+        with mock.patch.object(vif.LibvirtGenericVIFDriver,
+                               '_vrouter_port_add') as port_add:
+            d = vif.LibvirtGenericVIFDriver()
+            d.plug_vhostuser(self.instance, self.vif_vhostuser_vrouter)
+
+            port_add.assert_has_calls(calls['_vrouter_port_add'])
+
+    def test_vhostuser_vrouter_unplug(self):
+        calls = {
+            '_vrouter_port_delete': [mock.call(self.instance,
+                                     self.vif_vhostuser_vrouter)]
+        }
+        with mock.patch.object(vif.LibvirtGenericVIFDriver,
+                               '_vrouter_port_delete') as delete_port:
+            d = vif.LibvirtGenericVIFDriver()
+            d.unplug_vhostuser(self.instance, self.vif_vhostuser_vrouter)
+
+            delete_port.assert_has_calls(calls['_vrouter_port_delete'])
+
+    def test_vrouter_port_add(self):
+        ip_addr = '0.0.0.0'
+        ip6_addr = None
+        ptype = 'NovaVMPort'
+        cmd_args = ("--oper=add --uuid=%s --instance_uuid=%s --vn_uuid=%s "
+                    "--vm_project_uuid=%s --ip_address=%s --ipv6_address=%s"
+                    " --vm_name=%s --mac=%s --tap_name=%s --port_type=%s "
+                    "--tx_vlan_id=%d --rx_vlan_id=%d" %
+                    (self.vif_vhostuser_vrouter['id'],
+                    self.instance.uuid,
+                    self.vif_vhostuser_vrouter['network']['id'],
+                    self.instance.project_id, ip_addr, ip6_addr,
+                    self.instance.display_name,
+                    self.vif_vhostuser_vrouter['address'],
+                    self.vif_vhostuser_vrouter['devname'], ptype, -1, -1))
+        calls = {
+            'execute': [mock.call('vrouter-port-control', cmd_args,
+                                  run_as_root=True)]
+        }
+
+        with mock.patch.object(utils, 'execute') as execute_cmd:
+            d = vif.LibvirtGenericVIFDriver()
+            d._vrouter_port_add(self.instance, self.vif_vhostuser_vrouter)
+
+            execute_cmd.assert_has_calls(calls['execute'])
+
+    def test_vrouter_port_delete(self):
+        cmd_args = ("--oper=delete --uuid=%s" %
+                    (self.vif_vhostuser_vrouter['id']))
+        calls = {
+            'execute': [mock.call('vrouter-port-control', cmd_args,
+                        run_as_root=True)]
+        }
+
+        with mock.patch.object(utils, 'execute') as execute_cmd:
+            d = vif.LibvirtGenericVIFDriver()
+            d._vrouter_port_delete(self.instance, self.vif_vhostuser_vrouter)
+
+            execute_cmd.assert_has_calls(calls['execute'])
diff --git a/nova/virt/libvirt/config.py b/nova/virt/libvirt/config.py
index d48abdc..94e7ca6 100644
--- a/nova/virt/libvirt/config.py
+++ b/nova/virt/libvirt/config.py
@@ -509,6 +509,7 @@ class LibvirtConfigGuestCPUNUMACell(LibvirtConfigObject):
         self.id = None
         self.cpus = None
         self.memory = None
+        self.memAccess = None
 
     def parse_dom(self, xmldoc):
         if xmldoc.get("id") is not None:
@@ -517,6 +518,7 @@ class LibvirtConfigGuestCPUNUMACell(LibvirtConfigObject):
             self.memory = int(xmldoc.get("memory"))
         if xmldoc.get("cpus") is not None:
             self.cpus = hardware.parse_cpu_spec(xmldoc.get("cpus"))
+        self.memAccess = xmldoc.get("memAccess")
 
     def format_dom(self):
         cell = super(LibvirtConfigGuestCPUNUMACell, self).format_dom()
@@ -528,6 +530,8 @@ class LibvirtConfigGuestCPUNUMACell(LibvirtConfigObject):
                      hardware.format_cpu_spec(self.cpus))
         if self.memory is not None:
             cell.set("memory", str(self.memory))
+        if self.memAccess is not None:
+            cell.set("memAccess", self.memAccess)
 
         return cell
 
diff --git a/nova/virt/libvirt/driver.py b/nova/virt/libvirt/driver.py
index 1cf6c89..48b21db 100644
--- a/nova/virt/libvirt/driver.py
+++ b/nova/virt/libvirt/driver.py
@@ -3424,7 +3424,8 @@ class LibvirtDriver(driver.ComputeDriver):
                     setattr(guest.cputune, name,
                             int(flavor.extra_specs[key]))
 
-    def _get_cpu_numa_config_from_instance(self, instance_numa_topology):
+    def _get_cpu_numa_config_from_instance(self, instance_numa_topology,
+                                           wants_hugepages):
         if instance_numa_topology:
             guest_cpu_numa = vconfig.LibvirtConfigGuestCPUNUMA()
             for instance_cell in instance_numa_topology.cells:
@@ -3432,6 +3433,20 @@ class LibvirtDriver(driver.ComputeDriver):
                 guest_cell.id = instance_cell.id
                 guest_cell.cpus = instance_cell.cpuset
                 guest_cell.memory = instance_cell.memory * units.Ki
+
+                # The vhost-user network backend requires file backed
+                # guest memory (ie huge pages) to be marked as shared
+                # access, not private, so an external process can read
+                # and write the pages.
+                #
+                # You can't change the shared vs private flag for an
+                # already running guest, and since we can't predict what
+                # types of NIC may be hotplugged, we have no choice but
+                # to unconditionally turn on the shared flag. This has
+                # no real negative functional effect on the guest, so
+                # is a reasonable approach to take
+                if wants_hugepages:
+                    guest_cell.memAccess = "shared"
                 guest_cpu_numa.cells.append(guest_cell)
             return guest_cpu_numa
 
@@ -3443,6 +3458,28 @@ class LibvirtDriver(driver.ComputeDriver):
                     'Invalid libvirt version %(version)s') % {'version': ver_})
         return True
 
+    def _wants_hugepages(self, host_topology, instance_topology):
+        """Determine if the guest / host topology implies the
+           use of huge pages for guest RAM backing
+        """
+
+        if host_topology is None or instance_topology is None:
+            return False
+
+        avail_pagesize = [page.size_kb
+                          for page in host_topology.cells[0].mempages]
+        avail_pagesize.sort()
+        # Remove smallest page size as that's not classed as a largepage
+        avail_pagesize = avail_pagesize[1:]
+
+        # See if we have page size set
+        for cell in instance_topology.cells:
+            if (cell.pagesize is not None and
+                cell.pagesize in avail_pagesize):
+                return True
+
+        return False
+
     def _get_guest_numa_config(self, instance_numa_topology, flavor, pci_devs,
                                allowed_cpus=None):
         """Returns the config objects for the guest NUMA specs.
@@ -3483,9 +3520,11 @@ class LibvirtDriver(driver.ComputeDriver):
             raise exception.NUMATopologyUnsupported()
 
         topology = self._get_host_numa_topology()
+
         # We have instance NUMA so translate it to the config class
         guest_cpu_numa_config = self._get_cpu_numa_config_from_instance(
-                instance_numa_topology)
+                instance_numa_topology,
+                self._wants_hugepages(topology, instance_numa_topology))
 
         if not guest_cpu_numa_config:
             # No NUMA topology defined for instance - let the host kernel deal
diff --git a/nova/virt/libvirt/vif.py b/nova/virt/libvirt/vif.py
index 2d79dea..f5b7803 100644
--- a/nova/virt/libvirt/vif.py
+++ b/nova/virt/libvirt/vif.py
@@ -535,25 +535,8 @@ class LibvirtGenericVIFDriver(object):
         except processutils.ProcessExecutionError:
             LOG.exception(_LE("Failed while plugging vif"), instance=instance)
 
-    def plug_vhostuser(self, instance, vif):
-        ovs_plug = vif['details'].get(
-                                network_model.VIF_DETAILS_VHOSTUSER_OVS_PLUG,
-                                False)
-        if ovs_plug:
-            iface_id = self.get_ovs_interfaceid(vif)
-            port_name = os.path.basename(
-                    vif['details'][network_model.VIF_DETAILS_VHOSTUSER_SOCKET])
-            linux_net.create_ovs_vif_port(self.get_bridge_name(vif),
-                                          port_name, iface_id, vif['address'],
-                                          instance.uuid)
-            linux_net.ovs_set_vhostuser_port_type(port_name)
-
-    def plug_vrouter(self, instance, vif):
-        """Plug into Contrail's network port
-
-        Bind the vif to a Contrail virtual port.
-        """
-        dev = self.get_vif_devname(vif)
+    @staticmethod
+    def _vrouter_port_add(instance, vif):
         ip_addr = '0.0.0.0'
         ip6_addr = None
         subnets = vif['network']['subnets']
@@ -574,17 +557,60 @@ class LibvirtGenericVIFDriver(object):
         if (cfg.CONF.libvirt.virt_type == 'lxc'):
             ptype = 'NameSpacePort'
 
+        vif_type = 'Vrouter'
+        vhostuser_socket = ''
+        if vif['type'] == network_model.VIF_TYPE_VHOSTUSER:
+            vif_type = 'VhostUser'
+            vhostuser_socket = '--vhostuser_socket=%s' % \
+                vif['details'][network_model.VIF_DETAILS_VHOSTUSER_SOCKET]
+
         cmd_args = ("--oper=add --uuid=%s --instance_uuid=%s --vn_uuid=%s "
                     "--vm_project_uuid=%s --ip_address=%s --ipv6_address=%s"
                     " --vm_name=%s --mac=%s --tap_name=%s --port_type=%s "
-                    "--tx_vlan_id=%d --rx_vlan_id=%d" % (vif['id'],
-                    instance.uuid, vif['network']['id'],
+                    "--vif_type=%s %s --tx_vlan_id=%d --rx_vlan_id=%d" %
+                    (vif['id'], instance.uuid, vif['network']['id'],
                     instance.project_id, ip_addr, ip6_addr,
                     instance.display_name, vif['address'],
-                    vif['devname'], ptype, -1, -1))
+                    vif['devname'], ptype, vif_type, vhostuser_socket, -1, -1))
+
         try:
-            linux_net.create_tap_dev(dev)
             utils.execute('vrouter-port-control', cmd_args, run_as_root=True)
+        except processutils.ProcessExecutionError as e:
+            raise exception.VirtualInterfacePlugException(_("Failed to create "
+                "the vRouter port with the command: vrouter-port-control %s" %
+                cmd_args))
+
+    def plug_vhostuser(self, instance, vif):
+        ovs_plug = vif['details'].get(
+                                network_model.VIF_DETAILS_VHOSTUSER_OVS_PLUG,
+                                False)
+        vrouter_plug = vif['details'].get(
+                           network_model.VIF_DETAILS_VHOSTUSER_VROUTER_PLUG,
+                           False)
+        try:
+            if ovs_plug:
+                iface_id = self.get_ovs_interfaceid(vif)
+                port_name = os.path.basename(
+                        vif['details'][network_model.VIF_DETAILS_VHOSTUSER_SOCKET])
+                linux_net.create_ovs_vif_port(self.get_bridge_name(vif),
+                                              port_name, iface_id, vif['address'],
+                                              instance.uuid)
+                linux_net.ovs_set_vhostuser_port_type(port_name)
+
+            elif vrouter_plug:
+                self._vrouter_port_add(instance, vif)
+        except processutils.ProcessExecutionError:
+            LOG.exception(_LE("Failed while plugging vif"), instance=instance)
+
+    def plug_vrouter(self, instance, vif):
+        """Plug into Contrail's network port
+
+        Bind the vif to a Contrail virtual port.
+        """
+        dev = self.get_vif_devname(vif)
+        try:
+            linux_net.create_tap_dev(dev)
+            self._vrouter_port_add(instance, vif)
         except processutils.ProcessExecutionError:
             LOG.exception(_LE("Failed while plugging vif"), instance=instance)
 
@@ -741,15 +767,29 @@ class LibvirtGenericVIFDriver(object):
             LOG.exception(_LE("Failed while unplugging vif"),
                           instance=instance)
 
+    @staticmethod
+    def _vrouter_port_delete(instance, vif):
+        cmd_args = ("--oper=delete --uuid=%s" % (vif['id']))
+        utils.execute('vrouter-port-control', cmd_args, run_as_root=True)
+
     def unplug_vhostuser(self, instance, vif):
         ovs_plug = vif['details'].get(
                         network_model.VIF_DETAILS_VHOSTUSER_OVS_PLUG,
                         False)
-        if ovs_plug:
-            port_name = os.path.basename(
-                    vif['details'][network_model.VIF_DETAILS_VHOSTUSER_SOCKET])
-            linux_net.delete_ovs_vif_port(self.get_bridge_name(vif),
-                                          port_name)
+        vrouter_plug = vif['details'].get(
+                           network_model.VIF_DETAILS_VHOSTUSER_VROUTER_PLUG,
+                           False)
+        try:
+            if ovs_plug:
+                port_name = os.path.basename(
+                        vif['details'][network_model.VIF_DETAILS_VHOSTUSER_SOCKET])
+                linux_net.delete_ovs_vif_port(self.get_bridge_name(vif),
+                                              port_name)
+            elif vrouter_plug:
+                self._vrouter_port_delete(instance, vif)
+        except processutils.ProcessExecutionError:
+            LOG.exception(
+                _LE("Failed while unplugging vif"), instance=instance)
 
     def unplug_vrouter(self, instance, vif):
         """Unplug Contrail's network port
@@ -757,9 +797,8 @@ class LibvirtGenericVIFDriver(object):
         Unbind the vif from a Contrail virtual port.
         """
         dev = self.get_vif_devname(vif)
-        cmd_args = ("--oper=delete --uuid=%s" % (vif['id']))
         try:
-            utils.execute('vrouter-port-control', cmd_args, run_as_root=True)
+            self._vrouter_port_delete(instance, vif)
             linux_net.delete_net_dev(dev)
         except processutils.ProcessExecutionError:
             LOG.exception(
-- 
2.5.0

